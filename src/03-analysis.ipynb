{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b220c-debc-4415-bf95-1999f6f07543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "from tools import load_ana_data\n",
    "from glob import glob\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tools import lonlim, latlim, process_satellite_image, standardize_lat_lon, rasterize_geodataframe\n",
    "from shapely.geometry import box, Point, shape\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "fiona.drvsupport.supported_drivers['libkml'] = 'rw' # enable KML support which is disabled by default\n",
    "fiona.drvsupport.supported_drivers['LIBKML'] = 'rw' # enable KML support which is disabled by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dced75f-e878-4903-81e5-828faae10f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(\"../data/external/hydroweb/5-*\")\n",
    "\n",
    "ana = []\n",
    "station = []\n",
    "for fname in tqdm(fnames):\n",
    "    ana.append(load_ana_data(fname))\n",
    "    station.append(fname.split(\"-\")[-4])\n",
    "ana = xr.concat(ana, \"station\").assign_coords(station=station)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1039fa7-1579-46ae-b05c-9a3b5cda5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your longitude and latitude\n",
    "longitude = ana.longitude.values\n",
    "latitude = ana.latitude.values\n",
    "\n",
    "# Create a DataFrame for your point\n",
    "df = pd.DataFrame({\"longitude\": longitude, \"latitude\": latitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfc85d-cf5b-4460-8c1e-c9c562ba3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = dy = 30\n",
    "dlon = dx/(111.2e3*np.cos(latitude.mean()*np.pi/180))\n",
    "dlat = dy/(111.2e3)\n",
    "\n",
    "fnames = glob(f\"../data/external/swot/*\")\n",
    "fnames.sort()\n",
    "fnames = np.array(fnames)\n",
    "\n",
    "variables = [\n",
    "    \"height\", \"water_frac\", \"classification\",\n",
    "    \"geoid\", \"illumination_time\", \"pixel_area\"\n",
    "]\n",
    "\n",
    "heights = []\n",
    "for fname in tqdm(fnames):\n",
    "    swot = xr.open_dataset(fname, group=\"pixel_cloud\")[variables]\n",
    "    swot.load()\n",
    "    \n",
    "    for lon, lat, station in zip(ana.longitude.values, ana.latitude.values, ana.station.values):\n",
    "\n",
    "        where = (\n",
    "            (swot.longitude>lon-dlon)&(swot.longitude<lon+dlon)&\n",
    "            (swot.latitude>lat-dlat)&(swot.latitude<lat+dlat)\n",
    "        ).values\n",
    "        \n",
    "        ind = np.argwhere(where).ravel()\n",
    "\n",
    "        where = (\n",
    "            (swot.classification>2)&(swot.classification<6)&\n",
    "            (swot.water_frac>0.1)\n",
    "        )\n",
    "        dsi = swot.where(where).sel(points=ind)\n",
    "\n",
    "        dsi[\"water_level\"] = (dsi.height-dsi.geoid)\n",
    "        dsi = dsi.dropna(\"points\")\n",
    "        \n",
    "        if dsi.points.size>1:\n",
    "\n",
    "            level = xr.merge([\n",
    "                dsi.illumination_time.mean(),\n",
    "                dsi[\"water_level\"].median(),\n",
    "            ])\n",
    "\n",
    "            level[\"time\"] = level.illumination_time.mean()\n",
    "            level = level.set_coords(\"time\").drop_vars(\"illumination_time\").expand_dims(\"time\")\n",
    "\n",
    "            level = level.assign_coords(station=station).expand_dims(\"station\")\n",
    "            \n",
    "            heights.append(level)\n",
    "\n",
    "ana_swot = xr.merge(heights)\n",
    "ana_swot = ana_swot.isel(time=np.argsort(ana_swot.time.values))\n",
    "ana_swot = ana_swot.dropna(\"time\", how=\"all\")\n",
    "ana_swot[\"time\"] = ana_swot[\"time\"] - np.timedelta64(3, \"h\")\n",
    "ana_swot[\"time\"].attrs[\"timezone\"] = \"UTC-3\"\n",
    "\n",
    "correction = (ana.height.interp(time=ana_swot.time)-ana_swot.water_level).median()\n",
    "ana_swot[\"water_level\"] += correction\n",
    "ana_swot.attrs[\"correction (m)\"] = correction.values\n",
    "ana_swot[\"water_level\"].attrs = {\"units\": \"m\", \"long_name\": \"height above geoid\"}\n",
    "\n",
    "ana_swot.to_netcdf(\"../data/processed/swot_ana.nc\")\n",
    "ana.to_netcdf(\"../data/processed/ana.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09fde3-eb41-4f24-8696-6c9774751afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#e66231ff\", \"#1f59ffff\"]\n",
    "style = dict(marker=\"*\", lw=0, markersize=8, markeredgewidth=0.6, zorder=10, markeredgecolor=\"0.2\")\n",
    "\n",
    "before_i, after_i = 14, 15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "for time in ana_swot.time.values[[before_i, after_i]]:\n",
    "    ax.axvline(time, ls=\"--\", color=\"0.3\", alpha=0.6)\n",
    "    \n",
    "for station, color in zip(ana.station, colors):\n",
    "    ana_swot.water_level.sel(station=station).plot(ax=ax, x=\"time\", color=color, **style)\n",
    "    ana.sel(station=station).height.plot(ax=ax, x=\"time\", color=color, label=station.values)\n",
    "ax.grid(True, ls=\"--\", alpha=0.5)\n",
    "ax.legend()\n",
    "ax.set(title=\"\", xlabel=\"\", ylabel=\"water level [m]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf066203-68f2-443a-ae4d-d19b791ca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [\n",
    "    \"../data/external/landsat/before.nc\",\n",
    "    \"../data/external/landsat/after.nc\"\n",
    "]\n",
    "landsat = []\n",
    "for fname in fnames:\n",
    "    landsat.append(xr.open_dataset(fname).load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9490c-f3c0-45e3-b5d6-de8dfdc0c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_img = process_satellite_image(landsat[0])\n",
    "after_img = process_satellite_image(landsat[1])\n",
    "\n",
    "before_img = before_img.sel(longitude=slice(*lonlim), latitude=slice(*latlim))\n",
    "after_img = after_img.sel(longitude=slice(*lonlim), latitude=slice(*latlim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf283fd2-74f0-4e66-9a7b-51494c6a06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = landsat[0][\"SCL\"]\n",
    "\n",
    "mask = (da==6).astype('uint8').T\n",
    "mask = mask.rolling(lon=11, lat=11, center=True, min_periods=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009e4f1-c435-44e7-a29b-27d91364257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get resolution from the coordinate differences\n",
    "xres = (da.lon[1] - da.lon[0]).item()  # Convert to native Python float\n",
    "yres = (da.lat[0] - da.lat[1]).item()\n",
    "\n",
    "# Create the transform\n",
    "transform = rasterio.transform.from_origin(\n",
    "    da.lon[0], da.lat[0], xres, yres\n",
    ")\n",
    "\n",
    "# Convert the mask to shapes using rasterio.features.shapes\n",
    "shapes = list(rasterio.features.shapes(mask, transform=transform))\n",
    "\n",
    "# Filter out empty geometries (if any)\n",
    "valid_shapes = [(shape(geom), val) for geom, val in shapes if val == 1]  # val == 1 means the mask is True\n",
    "\n",
    "# Create a GeoDataFrame with the shapes and assign a CRS (if your raster has one)\n",
    "gdf = gpd.GeoDataFrame(geometry=[shape[0] for shape in valid_shapes], crs=da.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3188ba-8aef-459e-a404-f8611c59fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (landsat[1][\"SCL\"]==6).astype('uint8').T\n",
    "\n",
    "# Convert the mask to shapes using rasterio.features.shapes\n",
    "shapes = list(rasterio.features.shapes(mask, transform=transform))\n",
    "\n",
    "# Filter out empty geometries (if any)\n",
    "valid_shapes = [(shape(geom), val) for geom, val in shapes if val == 1]  # val == 1 means the mask is True\n",
    "\n",
    "# Create a GeoDataFrame with the shapes and assign a CRS (if your raster has one)\n",
    "scl_after = gpd.GeoDataFrame(geometry=[shape[0] for shape in valid_shapes], crs=da.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2fd436-25ff-442e-a039-f5de62541ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vertices(geom):\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        return len(geom.exterior.coords)\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        return sum(len(poly.exterior.coords) for poly in geom)\n",
    "    else:\n",
    "        return None  # Handle non-polygon geometries if present\n",
    "\n",
    "gdf[\"count\"] = gdf.geometry.apply(count_vertices)\n",
    "gdf = gdf[gdf[\"count\"]>400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c3a21-05e5-46fe-abd7-923e0ab8d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "flooded_areas = gpd.read_file(\"../data/external/ufrgs/inundacao_em_6_de_maio_de_2024.kml\")[[\"geometry\"]]\n",
    "crs = flooded_areas.crs\n",
    "flooded_areas[\"land\"] = True\n",
    "gdf[\"land\"] = False\n",
    "flooded_areas = pd.concat([flooded_areas.to_crs(4326), gdf[[\"geometry\", \"land\"]].to_crs(4326)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d31847-9680-4d81-9a61-3fdcfe2b46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = box(lonlim[0], latlim[0], lonlim[1], latlim[1])\n",
    "before_gdf = gpd.GeoDataFrame(geometry=[flooded_areas[flooded_areas.land==False].unary_union])\n",
    "after_gdf = gpd.GeoDataFrame(geometry=[flooded_areas.unary_union])\n",
    "\n",
    "before_gdf.crs=crs\n",
    "after_gdf.crs=crs\n",
    "\n",
    "before_gdf = gpd.clip(before_gdf, bbox)\n",
    "after_gdf = gpd.clip(after_gdf, bbox)\n",
    "\n",
    "before_raster = rasterize_geodataframe(before_gdf, lonlim, latlim, resolution=0.001)\n",
    "after_raster = rasterize_geodataframe(after_gdf, lonlim, latlim, resolution=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28fd06-5bbe-4c70-9d04-c691b38ade1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = standardize_lat_lon(xr.open_dataset(\"../data/external/landsat/elevation.nc\").elevation)\n",
    "elevation = elevation.sel(longitude=slice(*lonlim), latitude=slice(*latlim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b89e2-e19f-41f8-87be-7510814cfb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"../data/external/shapefiles/RM_Porto_Alegre/RM_PortoAlegre_UDH.shp\")\n",
    "gdf = gdf.rename({\"UDH_ATLAS\": \"udh\"}, axis=1)\n",
    "gdf[\"udh\"] = gdf[\"udh\"].astype(\"int\")\n",
    "gdf = gdf.set_index(\"udh\")\n",
    "\n",
    "fname = \"../data/external/shapefiles/RM_Porto_Alegre/atlasivs_dadosbrutos_Porto_Alegre.xlsx\"\n",
    "df = pd.read_excel(fname, sheet_name=\"UDH\")\n",
    "df = df[df.ano==2010].reset_index(drop=True).set_index(\"udh\")\n",
    "gdf = gdf.join(df.loc[gdf.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d54fa-a676-40a6-b19e-cb939b741750",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = gdf.intersection(bbox)\n",
    "perc_area = (intersection.to_crs(32722).area/gdf.to_crs(32722).area)\n",
    "gdf = gdf[perc_area>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d137d5c-febe-4d2b-9d5d-50748b23ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.hvplot(geo=True, color=\"ivs\")*before_gdf.hvplot(geo=True)*after_gdf.hvplot(geo=True, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668b838-57a8-4969-b5e6-69c59af19279",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = gdf.to_crs(32722).intersection(after_gdf.to_crs(32722).geometry.values[0]).area\n",
    "intersection = gdf.copy()\n",
    "intersection[\"intersection_area\"] = area\n",
    "intersection[\"area\"] = gdf.to_crs(32722).area\n",
    "intersection = intersection[intersection.intersection_area>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e4f50-4411-43e2-8b08-959bf5306990",
   "metadata": {},
   "outputs": [],
   "source": [
    "((intersection[\"populacao\"]*(intersection[\"t_vulner\"]/100)*(intersection[\"intersection_area\"]/intersection[\"area\"]))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d140b1-9682-42a1-8aaf-9d1d4a0027ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(intersection[\"populacao\"]*(intersection[\"intersection_area\"]/intersection[\"area\"])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f0276-8283-4927-8f6a-8859cb713953",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.prosp_soc.groupby(gdf.prosp_soc).count()/gdf.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29639bf-9b26-4980-a2e5-945b80cd2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection.prosp_soc.groupby(intersection.prosp_soc).count()/intersection.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74830d-a4d4-4f30-8997-a25430717a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "(intersection.ivs*intersection.populacao).sum()/intersection.populacao.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55108303-fc5d-43f8-9f7f-ee780e3ea2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gdf.ivs*gdf.populacao).sum()/gdf.populacao.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8904e99-e4c6-46c5-ae0f-4b2dc67a8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "(intersection.t_vulner*intersection.populacao/100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4513566-5c89-422a-9ee2-7cc29b542598",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gdf.t_vulner*1e-2*gdf.populacao).sum()/gdf.populacao.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d55dd3-c358-40f2-8211-d724ef6cbd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "(intersection.t_vulner*1e-2*intersection.populacao).sum()/intersection.populacao.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fed8b-9180-46aa-abd3-52ede9096a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.ivs.plot.hist(alpha=0.3, density=True, bins=np.arange(0, 0.5, 0.02))\n",
    "intersection.ivs.plot.hist(alpha=0.3, density=True, bins=np.arange(0, 0.5, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e54d65-ee8d-4966-90ca-4921f3832c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(f\"../data/external/swot/*\")\n",
    "fnames.sort()\n",
    "fnames = np.array(fnames)\n",
    "\n",
    "swot = []\n",
    "\n",
    "for i, (fname, raster) in enumerate(zip(fnames[[9, 11]], (before_raster, after_raster))):\n",
    "    swoti = standardize_lat_lon(xr.open_dataset(fname, group=\"pixel_cloud\")[variables])\n",
    "    swoti.load()\n",
    "\n",
    "    water = raster.interp(longitude=swoti.longitude, latitude=swoti.latitude, method=\"nearest\")\n",
    "    \n",
    "    where = (\n",
    "        (swoti.classification>2)&(swoti.classification<6)&\n",
    "        (swoti.water_frac>0.1)&(water==1)\n",
    "    )\n",
    "    \n",
    "    ind = np.argwhere(where.values).ravel()\n",
    "    \n",
    "    swoti = swoti.isel(points=ind)\n",
    "    \n",
    "    water_level = (swoti.height-swoti.geoid+correction).rename(\"water_level\")\n",
    "\n",
    "    swoti = swoti.where(water_level>0, drop=True)\n",
    "\n",
    "    water_level = water_level.where(water_level>0, drop=True)\n",
    "\n",
    "    elevation_swot = elevation.interp(longitude=water_level.longitude, latitude=water_level.latitude, method=\"nearest\").rename(\"elevation_srtm\")\n",
    "    water_depth = (water_level-elevation_swot).rename(\"water_depth\")\n",
    "    water_volume = (water_depth*swoti.pixel_area).rename(\"water_volume\")\n",
    "\n",
    "    swoti = xr.merge([swoti, water_depth, water_level, water_volume, elevation_swot])\n",
    "    \n",
    "    swot.append(swoti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6b9a1-7af3-46ff-a5e4-aae6eeadee3a",
   "metadata": {},
   "source": [
    "# Landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4031c8-4aa4-44a8-9b92-d5e233c1a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap_dict = {\n",
    "    10: '#006400',  # Tree cover\n",
    "    20: '#ffbb22',  # Shrubland\n",
    "    30: '#ffff4c',  # Grassland\n",
    "    40: '#f096ff',  # Cropland\n",
    "    50: '#fa0000',  # Built-up\n",
    "    60: '#b4b4b4',  # Bare / sparse vegetation\n",
    "    70: '#f0f0f0',  # Snow and ice\n",
    "    80: '#0064c8',  # Permanent water bodies\n",
    "    90: '#0096a0',  # Herbaceous wetland\n",
    "    95: '#00cf75',  # Mangroves\n",
    "    100: '#fae6a0', # Moss and lichen\n",
    "}\n",
    "clim = (2.5, 102.5)\n",
    "cmap = xr.DataArray([colormap_dict[i] for i in list(colormap_dict)], dims=[\"value\"], coords=dict(value=list(colormap_dict)))\n",
    "cmap = cmap.sel(value=np.arange(*clim,2.5), method=\"nearest\").assign_coords(value=np.arange(*clim,2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe120d5e-1ad2-47e8-9dd7-da38ca3c3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = standardize_lat_lon(xr.open_dataset(\"../data/external/landsat/landcover.nc\")).Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34269ff5-a1ea-4966-997c-fde04ea1885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_plot = landcover.hvplot(\n",
    "        x='longitude', \n",
    "        y='latitude',\n",
    "        geo=True,\n",
    "        rasterize=True, \n",
    "        clim=clim,\n",
    "        cmap=cmap.values.tolist(),\n",
    "        clabel=\"Land Cover Type\",\n",
    "        aggregator=\"mean\",\n",
    "        colorbar=False\n",
    "    )#.opts(cticks=list(colormap_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6f414-b72f-4b29-8b02-23aa9d015773",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9bda1-e5d4-411a-bea9-b42645e29bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (lonlim[0], lonlim[1])\n",
    "ylim = (latlim[0], latlim[1])\n",
    "\n",
    "kw = dict(\n",
    "    water_depth = dict(x=\"longitude\", y=\"latitude\", color=\"water_depth\", colorbar=False, geo=True, rasterize=True, clim=(0,9), x_sampling=0.0002, y_sampling=0.0002),\n",
    "    water_level = dict(x=\"longitude\", y=\"latitude\", color=\"water_level\", colorbar=False, geo=True, rasterize=True, clim=(0,7), x_sampling=0.0002, y_sampling=0.0002),\n",
    "    geoid = dict(x=\"longitude\", y=\"latitude\", color=\"geoid\", colorbar=False, geo=True, rasterize=True, clim=(4,6), x_sampling=0.0002, y_sampling=0.0002),\n",
    "    elevation = dict(geo=True, x=\"longitude\", y=\"latitude\", color=\"elevation\", rasterize=True, colorbar=False),\n",
    "    stations = dict(x=\"longitude\", y=\"latitude\", geo=True, color=\"red\"),\n",
    "    area = dict(geo=True, line_width=1, color=None),\n",
    "    rgb = dict(x=\"longitude\", y=\"latitude\", bands=\"bands\", geo=True, rasterize=True),\n",
    ")\n",
    "for k in kw:\n",
    "    kw[k] = dict(height=350, width=350, **kw[k])\n",
    "    # kw[k] = dict(xlim=xlim, ylim=ylim, **kw[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a88332-66f7-4b4e-9f5d-8940dd7945fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    swot[0].water_level.hvplot.points(**kw[\"water_level\"])+\n",
    "    swot[1].water_level.hvplot.points(**kw[\"water_level\"])+\n",
    "    swot[1].geoid.hvplot.points(**kw[\"geoid\"])+\n",
    "    np.log10(elevation).where(elevation>0,0).hvplot(**kw[\"elevation\"])\n",
    ").cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f6589-bbff-4582-8bb5-8b874b636ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_plot = (\n",
    "    (\n",
    "        before_img.hvplot.rgb(**kw[\"rgb\"])\n",
    "        *before_gdf.hvplot(**kw[\"area\"], line_color=\"blue\")\n",
    "        *after_gdf.hvplot(**kw[\"area\"], line_color=\"red\")\n",
    "    ).opts(title=\"a) Apr 15th 2024 (Landsat)\")+\n",
    "    (\n",
    "        landcover_plot*swot[0].water_depth.hvplot.points(**kw[\"water_depth\"])*\n",
    "        before_gdf.hvplot(**kw[\"area\"], line_color=\"blue\")*\n",
    "        after_gdf.hvplot(**kw[\"area\"], line_color=\"black\")\n",
    "    ).opts(title=\"b) water depth and land cover\")\n",
    ").cols(1)\n",
    "\n",
    "after_plot = (\n",
    "    (\n",
    "        after_img.hvplot.rgb(**kw[\"rgb\"])*\n",
    "        before_gdf.hvplot(**kw[\"area\"], line_color=\"blue\")*\n",
    "        after_gdf.hvplot(**kw[\"area\"], line_color=\"red\")\n",
    "    ).opts(title=\"c) May 6th 2024 (Landsat)\")+\n",
    "    (\n",
    "        swot[1].water_depth.hvplot.points(**kw[\"water_depth\"])*\n",
    "        before_gdf.hvplot(**kw[\"area\"], line_color=\"blue\")*\n",
    "        after_gdf.hvplot(**kw[\"area\"], line_color=\"red\")\n",
    "    ).opts(title=\"d) water depth\")\n",
    ").cols(1)\n",
    "\n",
    "(before_plot+after_plot).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4562e-fffe-4a7c-93de-bf844a5292a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "swot[1].water_depth.hvplot.points(x=\"longitude\", y=\"latitude\", color=\"water_depth\", geo=True, rasterize=True, clim=(0,9), x_sampling=0.0002, y_sampling=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26559bc2-d442-4633-b71d-aba63cfd142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = dict(\n",
    "    water_depth = dict(x=\"longitude\", y=\"latitude\", color=\"water_depth\", geo=True, rasterize=True, clim=(0,9), x_sampling=0.0002, y_sampling=0.0002),\n",
    "    water_level = dict(x=\"longitude\", y=\"latitude\", color=\"water_level\", geo=True, rasterize=True, clim=(0,7), x_sampling=0.0002, y_sampling=0.0002),\n",
    "    geoid = dict(x=\"longitude\", y=\"latitude\", color=\"geoid\", geo=True, rasterize=True, clim=(4,6), x_sampling=0.0002, y_sampling=0.0002),\n",
    "    elevation = dict(geo=True, x=\"longitude\", y=\"latitude\", color=\"elevation\", rasterize=True),\n",
    "    stations = dict(x=\"longitude\", y=\"latitude\", geo=True, color=\"red\"),\n",
    "    area = dict(geo=True, line_width=1, color=None),\n",
    "    rgb = dict(x=\"longitude\", y=\"latitude\", bands=\"bands\", geo=True, rasterize=True),\n",
    ")\n",
    "for k in kw:\n",
    "    kw[k] = dict(height=350, width=350, **kw[k])\n",
    "    # kw[k] = dict(xlim=xlim, ylim=ylim, **kw[k])\n",
    "\n",
    "(\n",
    "    swot[0].water_level.hvplot.points(**kw[\"water_level\"]).opts(title=\"Apr 15th 2024\")+\n",
    "    swot[1].water_level.hvplot.points(**kw[\"water_level\"]).opts(title=\"May 6th 2024\")+\n",
    "    swot[1].geoid.hvplot.points(**kw[\"geoid\"]).opts(title=\"Geoid\")+\n",
    "    np.log10(elevation).where(elevation>0,0).hvplot(**kw[\"elevation\"]).opts(title=\"SRTM elevation\")\n",
    ").cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4cfd9-8b90-4c49-9e6e-2b48f81e328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "swot[1].water_depth.hvplot.hist(bins=np.arange(-10,10,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0563c-5fa7-4a9b-b078-58256b5401de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = after_raster.interp(longitude=landcover.longitude, latitude=landcover.latitude)==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3be7e0-10ff-47ed-b2a9-c907f0db6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover.where(mask).plot.hist(bins=cmap.value.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c8e88-2fc0-4e71-9129-1f882b718f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area = (before_raster.size*(resolution*111.2e3)**2)\n",
    "npoints = before_raster.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d81e8-6bd3-4101-b6af-f1c4f1ff2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_before = total_area*before_raster.sum().values/npoints\n",
    "area_after = total_area*after_raster.sum().values/npoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069fdb93-604c-4adf-8a00-4aa3c4dada8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(area_after-area_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a25c7b-48ed-4642-8236-0041ecef7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_volume.sum().values/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6e556-9ab5-4744-9763-53e6f031578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_l = (((raster.size*(resolution*111.2e3)**2)/area.sum().values)*water_volume.sum().values/1000)*1e-6\n",
    "print(f\"{mi_l:0.2f} millions liters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621f8ec-c3bb-4c8a-ad66-08dabf8b144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columbia = (7500/1000)*1e-6\n",
    "(mi_l/columbia)/86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8947f87-c4e4-44f0-9329-59223ca978d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "((raster.size*(resolution*111.2e3)**2)/area.sum().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50952c-fe55-43a0-9409-50addccc574e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeaeb31-52a4-484c-94c0-dbd533263756",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = swot[1]\n",
    "\n",
    "dx = dy = 10000\n",
    "dlon = dx/(111.2e3*np.cos(latitudes.mean()*np.pi/180))\n",
    "dlat = dy/(111.2e3)\n",
    "\n",
    "n = 1000\n",
    "ind = np.random.randint(0, ds.points.size-1, n)\n",
    "longitudes, latitudes, water_levels = ds.longitude.values, ds.latitude.values, ds.water_level.values\n",
    "for lon, lat, water_level in tqdm(zip(longitudes[ind], latitudes[ind], water_levels[ind]), total=n):\n",
    "\n",
    "    where = (\n",
    "        (longitudes>lon-dlon)&(longitudes<lon+dlon)&\n",
    "        (latitudes>lat-dlat)&(latitudes<lat+dlat)\n",
    "    )\n",
    "    \n",
    "    i = np.argwhere(where).ravel()[np.random.randint(0, where.sum()-1, 5*n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5868c77-e04c-4a83-84e8-c92878aeeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(29.132/44.5, 23.9/44.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592d7b8-52b3-4b54-8f7d-29c7df29a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.sqrt((lon-longitudes[i])**2+(lat-latitudes[i])**2)\n",
    "correlation = (water_levels[i]-water_level)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d537d98-cf08-492d-b75b-cb66e3aa2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as ssd\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to model the Gaussian correlation function\n",
    "def gaussian_correlation(r, lc, epsilon):\n",
    "    return (1 - epsilon**2) * np.exp(-r**2 / lc**2)\n",
    "\n",
    "# Function to compute pairwise distances and correlations\n",
    "def compute_lengthscale(x, y, z, epsilon):\n",
    "    # Create an array of the coordinates\n",
    "    coords = np.column_stack((x, y))\n",
    "    \n",
    "    # Compute the pairwise distances\n",
    "    dists = ssd.pdist(coords)\n",
    "    dists_matrix = ssd.squareform(dists)\n",
    "    \n",
    "    # Compute the pairwise correlations\n",
    "    z_diffs = ssd.pdist(z[:, None])\n",
    "    correlations = np.exp(-z_diffs / z_diffs.std())\n",
    "    \n",
    "    # Fit the Gaussian correlation model to the data\n",
    "    params, _ = curve_fit(lambda r, lc: gaussian_correlation(r, lc, epsilon), dists, correlations)\n",
    "    lengthscale = params[0]\n",
    "    \n",
    "    return lengthscale, dists, correlations, params\n",
    "\n",
    "# Function to compute the gridded field using Objective Analysis (OA)\n",
    "def objective_analysis(x, y, z, lc, epsilon):\n",
    "    # Create an array of the coordinates\n",
    "    coords = np.column_stack((x, y))\n",
    "    \n",
    "    # Compute the pairwise distances\n",
    "    dists = ssd.pdist(coords)\n",
    "    dists_matrix = ssd.squareform(dists)\n",
    "    \n",
    "    # Compute the correlation matrix\n",
    "    C = gaussian_correlation(dists_matrix, lc, epsilon)\n",
    "    \n",
    "    # Compute the gridded field using the weighted observations\n",
    "    theta = np.dot(C, z) / C.sum(axis=1)\n",
    "    \n",
    "    return theta, dists_matrix, C\n",
    "\n",
    "# Generate synthetic data with a known correlation lengthscale\n",
    "def generate_synthetic_data(n_points, true_lengthscale, noise_level):\n",
    "    np.random.seed(0)\n",
    "    x = np.random.rand(n_points)\n",
    "    y = np.random.rand(n_points)\n",
    "    coords = np.column_stack((x, y))\n",
    "    \n",
    "    # Compute distances\n",
    "    dists = ssd.pdist(coords)\n",
    "    dists_matrix = ssd.squareform(dists)\n",
    "    \n",
    "    # Generate correlated z values with Gaussian correlation\n",
    "    z = np.exp(-dists_matrix / true_lengthscale).sum(axis=1)\n",
    "    \n",
    "    # Add noise\n",
    "    z += noise_level * np.random.randn(n_points)\n",
    "    \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae6f43-ba05-42fb-85a9-e754bb34132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_points = 2000\n",
    "true_lengthscale = 0.1\n",
    "noise_level = 0.5\n",
    "epsilon = 0.116  # Given in the image\n",
    "\n",
    "# Generate synthetic data\n",
    "x, y, z = generate_synthetic_data(n_points, true_lengthscale, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696017e7-1477-4c77-9a5a-fff7ceb4f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the correlation lengthscale\n",
    "lengthscale, dists, correlations, params = compute_lengthscale(x, y, z, epsilon)\n",
    "print(f\"True correlation lengthscale: {true_lengthscale:.4f}\")\n",
    "print(f\"Estimated correlation lengthscale: {lengthscale:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e06cf0-3048-458d-92ef-ea0f8e711fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Objective Analysis (OA)\n",
    "estimated_lengthscale = 0.1  # Initial guess for lc\n",
    "theta, dists_matrix, C = objective_analysis(x, y, z, estimated_lengthscale, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29cac3-4d0f-4a35-8908-50e3760564c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.scatter(x, y, c=theta-z, cmap='viridis', label='Gridded Field')\n",
    "plt.colorbar(label='Theta')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Gridded Field using Objective Analysis (OA)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06880842-6272-4b33-ac69-c4fed4fbc0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(z-theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2d5e7-3b4b-4bef-aeb9-c6c8e0747b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coringa",
   "language": "python",
   "name": "coringa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
